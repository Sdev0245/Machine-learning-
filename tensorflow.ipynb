{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deven Sharma \n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a =tf.constant(2)\n",
    "a # tconst 2:0 means how many times a consant is created \n",
    "# doesnt represnt value \n",
    "b=tf.constant(10)\n",
    "c=a + b # will not do addition like this \n",
    "# so in order to perform any operation we need to have tensor session\n",
    "sess =tf.Session()\n",
    "sess.run(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we don't need to write session again and again\n",
    "\n",
    "session = tf.Session()\n",
    "session.run(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# understanding the concept of variables \n",
    "# some data needs to be changed\n",
    "var1 = tf.Variable(10)\n",
    "var2 =tf.Variable(20)\n",
    "session = tf.Session()\n",
    "session.run(tf.global_variables_initializer()) # initialize with the session\n",
    "sum1 =tf.add(var1,var2)\n",
    "session.run(sum1) # now what the problem with the tensor flow is that we need to explicity define\n",
    "# that we are using the varibles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1022"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how to assign the value \n",
    "assign = var1.assign(1002)\n",
    "session.run(assign)\n",
    "session.run(sum1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# new type of way to store data using placeholders which helps to assign the values dynamically\n",
    "x = tf.placeholder('int32')\n",
    "y= x*tf.constant(10)\n",
    "\n",
    "session.run(y,feed_dict = {x:10})  # pass the feed dictionary that specify the value of the placholder\n",
    "# and the comman that need to be run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "(55000, 10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.]])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading the dataset \n",
    "# in the tensorflow\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "mnist =input_data.read_data_sets('MNIST_data/',one_hot =\"True\")\n",
    "mnist.train.images.shape\n",
    "print(mnist.train.labels.shape)\n",
    "mnist.train.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "first_image =  mnist.train.images[10]\n",
    "new_image= first_image.reshape((28,28))\n",
    "new_image = np.array(new_image,dtype ='float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f5548c66f60>"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(new_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.3838383]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    print(tf.random_normal([1]).eval())\n",
    "    # so one function is random_normal([n,m]) it takes n*m matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55000, 784)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.train.images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_input = 784\n",
    "hidden1 =256\n",
    "hidden2 =256\n",
    "bias1 =256\n",
    "bias2 =10\n",
    "classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights ={\n",
    "    'h1':tf.Variable(tf.random_normal([n_input,hidden1])),\n",
    "    'h2':tf.Variable(tf.random_normal([hidden1,hidden2])),\n",
    "    'out' :tf.Variable(tf.random_normal([hidden2,classes])),\n",
    "}    # initialzed the weights "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "biases  = {\n",
    "    'h1' :tf.Variable(tf.random_normal([hidden1])),\n",
    "    'h2':tf.Variable(tf.random_normal([hidden2])),\n",
    "     'out':tf.Variable(tf.random_normal([classes]))\n",
    "} #initilized the biases "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_pass(x,weights,biases):\n",
    "   \n",
    "    layer1_inp = tf.add(tf.matmul(x,weights['h1']),biases['h1'])\n",
    "   \n",
    "    layer1_op = tf.nn.relu(layer1_inp) # relu is a neural networks activation function\n",
    "    layer2_inp = tf.add(tf.matmul(layer1_op,weights['h2']),biases['h2'])\n",
    "    layer2_op = tf.nn.relu(layer2_inp)\n",
    "     \n",
    "    act_op =  tf.add(tf.matmul(layer2_op,weights['out']),biases['out'])\n",
    "    \n",
    "    return act_op\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "x =tf.placeholder('float',[None,n_input])\n",
    "y =tf.placeholder('int32',[None,classes])\n",
    "\n",
    "session = tf.Session()\n",
    "# session.run(tf.global_variables_initializer())\n",
    "pred = forward_pass(x,weights,biases)\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits =pred,labels=y)) # this is cost function\n",
    "# how to use the inbuilt optimizer let's see\n",
    "tf.train\n",
    "prediction  =tf.argmax(pred,1)\n",
    "label = tf.argmax(y,1)\n",
    "transformed =tf.equal(prediction,label)\n",
    "# pred1,temp,actual = session.run([prediction,transformed,label],feed_dict={x:mnist.train.images,y:mnist.train.labels})\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2920.575]\n",
      "[2920.575]\n"
     ]
    }
   ],
   "source": [
    "# tf we need to find the cost we can use the cross entropy\n",
    "# the cross entropy function takes two things one is logit =prediction and othe is label\n",
    "# firstly using the argmax for finding the max value of the specific index \n",
    "\n",
    "# here we will be using the cross entropy \n",
    "# let use an optimizer\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate =0.01)\n",
    "optimize = optimizer.minimize(cost)\n",
    "session.run(tf.global_variables_initializer())\n",
    "for i in range(2):\n",
    "   print( session.run([cost],feed_dict ={x:mnist.train.images,y:mnist.train.labels}))\n",
    "   \n",
    "    # one more thing can be done \n",
    "# batch gradient can be applied as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "# so how does an optimizer work actually what happend that the optimizer find out the weights whsose value\n",
    "# depend on the cost then it only changes those weights \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "# working  with the keras\n",
    "# things to do \n",
    "# create a model\n",
    "# define architcture =====>\n",
    "                            #layers =>units =>activation_function=>compiling\n",
    "    \n",
    "    # we can create a sequential models \n",
    "    \n",
    "    # we can have multiple input and output model\n",
    "    # we can have functional(APi) model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "model =Sequential()\n",
    "model.add(Dense(30,input_dim = 30,activation ='relu'))\n",
    "model.add(Dense(30,activation ='relu'))\n",
    "model.add(Dense(1,activation ='sigmoid'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model.compile(optimizer = 'adam',loss ='binary_crossentropy',metrics =['accuracy'])\n",
    "from sklearn import datasets\n",
    "\n",
    "data = datasets.load_breast_cancer()\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train , x_test ,y_train, y_test  = train_test_split(data.data,data.target ,test_size = 0.3,random_state =0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model.compile(optimizer = 'adam',loss ='binary_crossentropy',metrics =['accuracy'])  # loss is differnct for different problems\n",
    "# optimizer tries to optimize the cost\n",
    "from sklearn import datasets\n",
    "\n",
    "data = datasets.load_breast_cancer()\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "st =StandardScaler()\n",
    "x_train , x_test ,y_train, y_test = train_test_split(data.data,data.target ,test_size = 0.3,random_state =0)\n",
    "x_train = st.fit_transform(x_train)\n",
    "x_test= st.fit_transform(x_test)\n",
    "model.fit(x_train,y_train,epochs =20,batch_size =110)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0000000e+00],\n",
       "       [9.8561203e-01],\n",
       "       [1.0000000e+00],\n",
       "       [9.9999899e-01],\n",
       "       [1.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [1.1615634e-02],\n",
       "       [9.9965334e-01],\n",
       "       [1.0000000e+00],\n",
       "       [2.1324158e-03],\n",
       "       [3.9646029e-04],\n",
       "       [0.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [9.9985224e-01],\n",
       "       [0.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [9.9995732e-01],\n",
       "       [0.0000000e+00],\n",
       "       [9.9999976e-01],\n",
       "       [0.0000000e+00],\n",
       "       [4.1723251e-06],\n",
       "       [1.0000000e+00],\n",
       "       [2.0325184e-05],\n",
       "       [1.0000000e+00],\n",
       "       [9.9999994e-01],\n",
       "       [0.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [9.9985844e-01],\n",
       "       [1.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [3.1292439e-06],\n",
       "       [0.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [9.9999964e-01],\n",
       "       [9.9996424e-01],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [9.2559659e-01],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [5.4425657e-02],\n",
       "       [0.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [1.3699830e-03],\n",
       "       [0.0000000e+00],\n",
       "       [9.9940014e-01],\n",
       "       [1.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [8.7140501e-03],\n",
       "       [3.9160579e-02],\n",
       "       [0.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [9.9999988e-01],\n",
       "       [1.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [9.9999976e-01],\n",
       "       [9.9975473e-01],\n",
       "       [0.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [9.8114449e-01],\n",
       "       [4.3252075e-01],\n",
       "       [1.1572242e-03],\n",
       "       [9.9999833e-01],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [8.9311779e-01],\n",
       "       [1.0000000e+00],\n",
       "       [9.9999243e-01],\n",
       "       [9.9979699e-01],\n",
       "       [9.9999970e-01],\n",
       "       [9.9970078e-01],\n",
       "       [1.0000000e+00],\n",
       "       [9.9998927e-01],\n",
       "       [1.0000000e+00],\n",
       "       [9.9998891e-01],\n",
       "       [1.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [9.9995315e-01],\n",
       "       [1.9282171e-01],\n",
       "       [1.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [9.9989831e-01],\n",
       "       [1.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [8.2936382e-01],\n",
       "       [1.9582063e-02],\n",
       "       [0.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [9.9999034e-01],\n",
       "       [5.0663948e-07],\n",
       "       [1.0000000e+00],\n",
       "       [9.9999952e-01],\n",
       "       [1.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [9.9999988e-01],\n",
       "       [2.9451019e-01],\n",
       "       [1.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [9.9998653e-01],\n",
       "       [1.1920929e-07],\n",
       "       [1.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [9.9926430e-01],\n",
       "       [9.9999940e-01],\n",
       "       [1.0000000e+00]], dtype=float32)"
      ]
     },
     "execution_count": 426,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
