{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/deven/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# in order to improve the accuracy we need to process the document using nlp\n",
    "# context of word should be maintained\n",
    "# words should be used as features\n",
    "from nltk.tokenize import sent_tokenize,word_tokenize\n",
    "sample_text = \"Let's see the working of this thing and check if it works or not?\"\n",
    "sent_tokenize(sample_text)\n",
    "words_check = word_tokenize(sample_text)\n",
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next thing is we want to remove the stop words using corpus use the stopwords.words(\"_language in which u want\")\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop = stopwords.words('english')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# convert all the words to lower case \n",
    "# but it may be useful sometimes the time \n",
    "# we also need to remove the punctuation \n",
    "# what we can do  is to use the function in string library called punctuation\n",
    "\n",
    "import string \n",
    "punctuation = string.punctuation\n",
    "print(punctuation)\n",
    "\n",
    "stop = list(punctuation)+stop\n",
    "clean_words = [w for w in words_check if not w in stop]  #stroing the clean words \n",
    "print(clean_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/deven/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['play', 'happier', 'sampl']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we want also the root word of the word eg better === > good\n",
    "\n",
    "from nltk.stem import PorterStemmer  # porter stemmer is used for the stemming \n",
    "\n",
    "# create a obj of porter stemmer then we need to call stem on each of words\n",
    "stemmed_words = ['played','happier','sampled']\n",
    "\n",
    "stemming = PorterStemmer()\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "stem=  [stemming.stem(w) for w in stemmed_words]   # it provides a function stem\n",
    "stem # but the PorterStemmer is actually rule based "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/deven/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('This', 'DT'), ('painting', 'NN'), ('is', 'VBZ'), ('very', 'RB'), ('beautiful', 'JJ')]\n"
     ]
    }
   ],
   "source": [
    "# understanding part of the speech \n",
    "# the part of speech is used which type of word it is ie noun,adjective\n",
    "\n",
    "from nltk import pos_tag\n",
    "checker = \"This painting is very beautiful\"\n",
    "tags = pos_tag(word_tokenize(checker))\n",
    "nltk.download('wordnet')\n",
    "print(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stemming is not that great because its rule based \n",
    "# for that we use the lemmitization(much powerful)\n",
    "# but lemmitization has some  requirement \n",
    "\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "cal = lemmatizer.lemmatize(\"painting\",pos='v')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'movie_review'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-77-380488134ca3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# lets work on the movie review dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# task  : to create a classifier that is trained on the dataset and then perform the operation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmovie_review\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'movie_review'"
     ]
    }
   ],
   "source": [
    "# lets work on the movie review dataset \n",
    "# task  : to create a classifier that is trained on the dataset and then perform the operation \n",
    "from nltk.corpus import movie_review"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
